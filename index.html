
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>wtf AI ?</title>
  <meta name="author" content="Xusen">

  
  <meta name="description" content="以及发发牢骚 :&ndash;) 稀疏向量的支持：自然数据中的稀疏属性的挖掘和支持 现在来探索如何在大数据中归约数据量，降低计算复杂度。本文两侧分治之，其一，通过发掘和支持自然数据中的稀疏属性，算作自然资源的挖掘；其二，通过对现有数据的聚集归约，视为人工数据聚合。这两种方法在 MLlib &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://yinxusen.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="wtf AI ?" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">wtf AI ?</a></h1>
  
    <h2>Gee...  I don't know what AI means...</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:yinxusen.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/aboutme">About Me</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/08/20/mllib-sparsity/">MLlib：归约数据量</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-08-20T19:01:03+08:00" pubdate data-updated="true">Aug 20<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>以及发发牢骚 :&ndash;)</h2>

<h2>稀疏向量的支持：自然数据中的稀疏属性的挖掘和支持</h2>

<p>现在来探索如何在大数据中归约数据量，降低计算复杂度。本文两侧分治之，其一，通过发掘和支持自然数据中的稀疏属性，算作自然资源的挖掘；其二，通过对现有数据的聚集归约，视为人工数据聚合。这两种方法在 MLlib 中均得到了很好的体现。本篇旨在剖析 MLlib 现有的两类数据归约方法，权当为后来的机器学习分布式算法抛砖引玉。</p>

<p>自从 Spark 1.0 以来，MLlib 开始透过<code>Vector</code>接口支持稀疏向量。并在下层以 Breeze 承接计算主体。这一改变影响巨大，首先现有的几乎所有算法都遭到了随之而来的改动。从用于矩阵分解的 ALS、SVD，到所有的线性模型，乃至朴素贝叶斯和 K 均值算法都在改动之列。新加入的决策树算法因其起步晚，所以一开始就享受到稀疏向量带来的优势。甚至可以说，正是稀疏矩阵的加入，让 MLlib 由一个 demo 式的玩具，变成了可以工业应用的平台。</p>

<h3>稀疏性</h3>

<p>稀疏性是自然世界的本质属性。在大数据时代的数据几乎是稀疏数据的天下。稀疏性来源于两个方面，一是数据“基”非常大，即数据空间之大；二是数据“点”非常少，即可观测的性征少。N-Gram 是前者，数据空间大小以全体文字数目为幂次，而世界上能出现的N个文字的组合却远少于这个值。点评数据是后者，由于长尾因素，大多数用户能点评的数据非常有限，因此仅填充了“用户——物品”矩阵很少的一部分。</p>

<p>从统计学家，或者机器学习人员的角度来看，现实世界的数据等于稀疏数据（或者低秩数据）加上噪声。而这正是机器学习算法能够成功过的一个重要基础。统计学家和机器学习人员的一个重要工作就是在貌似繁杂的数据中找到那些简单的构造因素。有点类似于牛顿三定律，不论世界多么复杂，物质作用多么繁复，只要是在经典力学的范围内，就要遵循三定律。三定律就是世界的模型，由此构成稀疏的世界。一幅图像是稠密的，其内部充斥着 RGB 三原色的组合，并且大都不为零。一个神经讯号是稠密的，在时间线上连续存在。对于这种数据，我们可以通过小波变换或者傅里叶变换找到它稀疏的一面。</p>

<p>如果把数据点除以数据空间作为数据密度，那么 Netflix 竞赛数据的密度只有 1.17%，rcv1 数据集的数据密度仅 0.15%，近些年来所用到的欺诈检测的数据平均密度仅有 10%，而且这些数据为了提取更多的特征，通常都人为增大了欺诈数据的条目，即是有偏的！现在估算一下你手头数据的数据密度，是否要考虑稀疏性了呢？那么应该怎么做？核心就是要善于发现和利用这种属性。Spark 1.0 加入了稀疏向量，正是往实际应用迈进了临门一脚。</p>

<p>有了稀疏向量只是一个基础，说明我们有能力发掘现实世界的稀疏性了。然而下一步更重要的是，如何在机器学习算法中更好的利用这种性质？要知道，稀疏性无处不在，但又非常脆弱，很多操作就能破坏它。例如向量加法，两个稀疏向量相加的结果会比之前的向量稠密一些，多个向量相加的结果就完全是稠密矩阵了。因此，善于利用利于保持稀疏性的线性代数运算是其中的关键。</p>

<h3>K 均值的稀疏算法</h3>

<p>最典型的成功案例就是 K 均值算法。同样的数据集，在利用稀疏向量之后，不仅省下了大量的存储空间（是数据密度而定），更能让程序加速数倍。K 均值是一个典型的 Expectation-Maximization 算法。即首先在固定聚类中心的前提下求期望（这里是到各中心点的最小距离），然后是固定每个样本类属后最优化中心点（这里就是简单的求均值）。而这个距离计算深深地出卖了 K 均值算法。中心点一般而言都是求均值之后的结果，求均值恰好是一堆稀疏向量求和的过程，因此中心点这个向量一般而言都是稠密的。一个稠密的向量和一个稀疏的样本在求距离的时候很显然是稠密矩阵占优，因为两个向量之间做减法。如此一来，数据本身的稀疏性就被大大的破坏了。为此我们要寻求解决之道。</p>

<p>解决之道就在距离计算公式中，该公式可以拆分为两个 norm 的计算和一个点积的计算。样本本身是稀疏的，因此其 norm 计算也是稀疏的，并且这个值是不变的，可以先期计算好；中心点本身是稠密的，但是其在 expectation 的计算过程中不变，所以只需要计算一次就好；剩下的点积是稀疏向量占优的。这样我们就立马解决了刚才的难题，极大地降低了计算量。</p>

<h3>线性模型的稀疏算法</h3>

<p>下一个比较成功的案例是线性模型。线性模型每次迭代计算的本质是求梯度，而梯度也是样本数据与某种求偏导得来的向量的点积，因此在求每一个样本点的梯度的时候，可以很好的利用稀疏的性质。下面问题来了，梯度在做聚合的时候，如果直接用稀疏向量的加法把这些梯度全部累加起来，其实是非常要命的。首先，根据刚才所言，多个稀疏向量相加最终结果一般是稠密矩阵；其次，根据稀疏向量的定义，要生成很多不必要的临时对象，造成严重的 GC。因此，MLlib 采取的做法是用一个稠密向量作为初始值，将稀疏向量聚合到这个稠密向量上，因此降低了计算的难度。</p>

<h3>统计值的稀疏性算法</h3>

<p>统计值个数、均值、最大最小值、非零元以及方差更是探索稀疏性的便宜之所。首先通过使用流式均值、方差算法，可以再对数据的一遍扫描后得到这六种统计值。其次，由于稀疏性的存在，再次将算法复杂度由 O(nd) 降到 O(nnz)。</p>

<h3>SVD 的稀疏性算法</h3>

<p>MLlib 探索稀疏性的最后一例是奇异值分解（SVD）。类似于 ALS，SVD 也是一种常用的推荐算法，并且是由传统的线性代数转换而来。至于 ALS 算法，笔者在 2014 年 8 月期的《程序员》中已作详细的介绍。SVD 在计算上与特征值/特征向量求解是高度相关的，（这里是一些公式）。在使用 Lanczos 算法求解特征值分解的时候，有大量的矩阵与向量乘积运算。因此，在内积计算的时候可以很好的利用稀疏性，而在向量累加的时候利用跟线性模型一样的做法即可。</p>

<p>花开两朵，各表一枝。对于无法直接利用稀疏性来降低计算复杂度的算法来说，人工归约与压缩可能是另外的途径。MLlib 中决策树算法的实现是其中很明显的代表。</p>

<h2>决策树算法的实现：人为的数据规约降低计算复杂度</h2>

<h3>决策树算法</h3>

<p>决策树算法是所有机器学习方法中最容易解释的一种了。依据人工智能的发展史，决策树的祖先可以追溯到上世纪50年代的符号推理模型。John McCarthy等人意图用逻辑与符号表达人类思维过程。而决策树本身可以算作符号推理派和统计学派的“结晶”。</p>

<p>决策树的故事是从一张表开始的。这张表的行是样本，列是特征。每一次决策的过程都会遍历这个表所有的项，从中找到一个最合适的，这次决策就表示为：如果某个样本该特征的值大于当前选择的项，那么属于右边子树中的类，否则属于左边子树中的类。因此决策树其实很简单，站在每个节点上，面对这个节点中有的数据，选择一个“最合适的”表项进行分裂。“最合适的”表项有多种选择，MLlib官方文档就有很详细的介绍，这里不再赘述。</p>

<h3>数据采样、分割</h3>

<p>这里问题就来了。假设数据有千千万，我怎样才能高效的处理这些数据，并从中找到我需要的表项呢？可行的方案之一就是采样，可以使在样本这个级别采样，也可以是在特征这个级别采样，甚至两个方向同时采样。但是这种采样一般都伴随着组合模型，如果单纯训练一棵树，采样比例过低的话会导致效果不好。尤其是，我们无法保证数据本身是随机分布的，因此难以保证随机采样的准确性。</p>

<p>另一个方法是做data parallel，每个数据划分进行自己的决策树训练，最终的结果混合到一起做模型组合。这种想法比较直接，而且可以复用单机的决策树训练算法。但是如果出现了比较极端的情况会导致单个机器上的决策树训练失败。比如每个机器上的数据都不具有可区分性，其各个特征方向方差都很小，而不同的data partition之间方差很大，这样导致单个数据划分内部效果不好。甚至很多情况下都会存在这种问题，即每个数据分片内部数据比较相似，而分片之间数据差异很大。</p>

<h3>决策树的三大优化算法</h3>

<p>于是一个百来行就能写完的程序扩展成将近2000行的“巨无霸”（很多MLlib的程序都面临着这种境况）。<strong>（其实我现在越来越觉得能把简单的程序写的这么复杂不是好事儿，肯定是哪个地方的抽象出问题了。）</strong> MLlib实现的决策树共有三种分布式程序优化方法，一是聚合代替shuffle，二是分桶减少计算，三是逐层训练降低数据扫描次数。下面一一道来。</p>

<p>先看决策树算法的主干（简单起见删了很多不重要的语句）：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'> <span class="k">def</span> <span class="n">train</span><span class="o">(</span><span class="n">input</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">LabeledPoint</span><span class="o">])</span><span class="k">:</span> <span class="kt">DecisionTreeModel</span> <span class="o">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="o">(</span><span class="n">splits</span><span class="o">,</span> <span class="n">bins</span><span class="o">)</span> <span class="k">=</span> <span class="nc">DecisionTree</span><span class="o">.</span><span class="n">findSplitsBins</span><span class="o">(</span><span class="n">retaggedInput</span><span class="o">,</span> <span class="n">metadata</span><span class="o">)</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">nodes</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Node</span><span class="o">](</span><span class="n">maxNumNodes</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">var</span> <span class="n">level</span> <span class="k">=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="k">var</span> <span class="n">break</span> <span class="k">=</span> <span class="kc">false</span>
</span><span class='line'>    <span class="k">while</span> <span class="o">(</span><span class="n">level</span> <span class="o">&lt;=</span> <span class="n">maxDepth</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">break</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">splitsStatsForLevel</span> <span class="k">=</span> <span class="nc">DecisionTree</span><span class="o">.</span><span class="n">findBestSplits</span><span class="o">(</span><span class="n">treeInput</span><span class="o">,</span> <span class="n">parentImpurities</span><span class="o">,</span>
</span><span class='line'>        <span class="n">metadata</span><span class="o">,</span> <span class="n">level</span><span class="o">,</span> <span class="n">nodes</span><span class="o">,</span> <span class="n">splits</span><span class="o">,</span> <span class="n">bins</span><span class="o">,</span> <span class="n">maxLevelForSingleGroup</span><span class="o">,</span> <span class="n">timer</span><span class="o">)</span>
</span><span class='line'>      <span class="k">for</span> <span class="o">((</span><span class="n">nodeSplitStats</span><span class="o">,</span> <span class="n">index</span><span class="o">)</span> <span class="k">&lt;-</span> <span class="n">splitsStatsForLevel</span><span class="o">.</span><span class="n">view</span><span class="o">.</span><span class="n">zipWithIndex</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">extractNodeInfo</span><span class="o">(</span><span class="n">nodeSplitStats</span><span class="o">,</span> <span class="n">level</span><span class="o">,</span> <span class="n">index</span><span class="o">,</span> <span class="n">nodes</span><span class="o">)</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">val</span> <span class="n">topNode</span> <span class="k">=</span> <span class="n">nodes</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
</span><span class='line'>    <span class="n">topNode</span><span class="o">.</span><span class="n">build</span><span class="o">(</span><span class="n">nodes</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">new</span> <span class="nc">DecisionTreeModel</span><span class="o">(</span><span class="n">topNode</span><span class="o">,</span> <span class="n">strategy</span><span class="o">.</span><span class="n">algo</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>通过这个还算清晰的框架，可以看出决策树训练共有三步，一是<code>findSplitsBins</code>，其作用是将原始数据按照特征的维度分桶。二是while循环中的<code>findBestSplits</code>，目的是在决策树每层节点的训练中为每个节点找到最佳的分裂点。最后一步是构造决策树。</p>

<p>现在寻根溯源，首先看看数据按特征分桶是怎么做的：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'> <span class="k">protected</span><span class="o">[</span><span class="kt">tree</span><span class="o">]</span> <span class="k">def</span> <span class="n">findSplitsBins</span><span class="o">(</span>
</span><span class='line'>      <span class="n">input</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">LabeledPoint</span><span class="o">],</span>
</span><span class='line'>      <span class="n">metadata</span><span class="k">:</span> <span class="kt">DecisionTreeMetadata</span><span class="o">)</span><span class="k">:</span> <span class="o">(</span><span class="kt">Array</span><span class="o">[</span><span class="kt">Array</span><span class="o">[</span><span class="kt">Split</span><span class="o">]],</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Array</span><span class="o">[</span><span class="kt">Bin</span><span class="o">]])</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">val</span> <span class="n">requiredSamples</span> <span class="k">=</span> <span class="n">numBins</span><span class="o">*</span><span class="n">numBins</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">fraction</span> <span class="k">=</span> <span class="k">if</span> <span class="o">(</span><span class="n">requiredSamples</span> <span class="o">&lt;</span> <span class="n">count</span><span class="o">)</span> <span class="n">requiredSamples</span><span class="o">.</span><span class="n">toDouble</span> <span class="o">/</span> <span class="n">count</span> <span class="k">else</span> <span class="mf">1.0</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">val</span> <span class="n">sampledInput</span> <span class="k">=</span>
</span><span class='line'>      <span class="n">input</span><span class="o">.</span><span class="n">sample</span><span class="o">(</span><span class="n">withReplacement</span> <span class="k">=</span> <span class="kc">false</span><span class="o">,</span> <span class="n">fraction</span><span class="o">,</span> <span class="k">new</span> <span class="nc">XORShiftRandom</span><span class="o">().</span><span class="n">nextInt</span><span class="o">()).</span><span class="n">collect</span><span class="o">()</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">numSamples</span> <span class="k">=</span> <span class="n">sampledInput</span><span class="o">.</span><span class="n">length</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">val</span> <span class="n">stride</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="n">numSamples</span><span class="o">.</span><span class="n">toDouble</span> <span class="o">/</span> <span class="n">numBins</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">metadata</span><span class="o">.</span><span class="n">quantileStrategy</span> <span class="k">match</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">case</span> <span class="nc">Sort</span> <span class="k">=&gt;</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">splits</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">.</span><span class="n">ofDim</span><span class="o">[</span><span class="kt">Split</span><span class="o">](</span><span class="n">numFeatures</span><span class="o">,</span> <span class="n">numBins</span> <span class="o">-</span> <span class="mi">1</span><span class="o">)</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">bins</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">.</span><span class="n">ofDim</span><span class="o">[</span><span class="kt">Bin</span><span class="o">](</span><span class="n">numFeatures</span><span class="o">,</span> <span class="n">numBins</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>        <span class="c1">// Find all splits.</span>
</span><span class='line'>
</span><span class='line'>        <span class="c1">// Iterate over all features.</span>
</span><span class='line'>        <span class="k">var</span> <span class="n">featureIndex</span> <span class="k">=</span> <span class="mi">0</span>
</span><span class='line'>        <span class="k">while</span> <span class="o">(</span><span class="n">featureIndex</span> <span class="o">&lt;</span> <span class="n">numFeatures</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>          <span class="c1">// Check whether the feature is continuous.</span>
</span><span class='line'>          <span class="k">val</span> <span class="n">isFeatureContinuous</span> <span class="k">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">isContinuous</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">)</span>
</span><span class='line'>          <span class="k">if</span> <span class="o">(</span><span class="n">isFeatureContinuous</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="k">val</span> <span class="n">featureSamples</span> <span class="k">=</span> <span class="n">sampledInput</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">lp</span> <span class="k">=&gt;</span> <span class="n">lp</span><span class="o">.</span><span class="n">features</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">)).</span><span class="n">sorted</span>
</span><span class='line'>            <span class="k">val</span> <span class="n">stride</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="n">numSamples</span><span class="o">.</span><span class="n">toDouble</span> <span class="o">/</span> <span class="n">numBins</span>
</span><span class='line'>            <span class="n">logDebug</span><span class="o">(</span><span class="s">&quot;stride = &quot;</span> <span class="o">+</span> <span class="n">stride</span><span class="o">)</span>
</span><span class='line'>            <span class="k">for</span> <span class="o">(</span><span class="n">index</span> <span class="k">&lt;-</span> <span class="mi">0</span> <span class="n">until</span> <span class="n">numBins</span> <span class="o">-</span> <span class="mi">1</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>              <span class="k">val</span> <span class="n">sampleIndex</span> <span class="k">=</span> <span class="n">index</span> <span class="o">*</span> <span class="n">stride</span><span class="o">.</span><span class="n">toInt</span>
</span><span class='line'>              <span class="c1">// Set threshold halfway in between 2 samples.</span>
</span><span class='line'>              <span class="k">val</span> <span class="n">threshold</span> <span class="k">=</span> <span class="o">(</span><span class="n">featureSamples</span><span class="o">(</span><span class="n">sampleIndex</span><span class="o">)</span> <span class="o">+</span> <span class="n">featureSamples</span><span class="o">(</span><span class="n">sampleIndex</span> <span class="o">+</span> <span class="mi">1</span><span class="o">))</span> <span class="o">/</span> <span class="mf">2.0</span>
</span><span class='line'>              <span class="k">val</span> <span class="n">split</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Split</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">,</span> <span class="n">threshold</span><span class="o">,</span> <span class="nc">Continuous</span><span class="o">,</span> <span class="nc">List</span><span class="o">())</span>
</span><span class='line'>              <span class="n">splits</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">)(</span><span class="n">index</span><span class="o">)</span> <span class="k">=</span> <span class="n">split</span>
</span><span class='line'>            <span class="o">}</span>
</span><span class='line'>          <span class="o">}</span> <span class="k">else</span> <span class="o">{</span> <span class="o">???</span> <span class="o">}</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>        <span class="c1">// Find all bins.</span>
</span><span class='line'>        <span class="n">featureIndex</span> <span class="k">=</span> <span class="mi">0</span>
</span><span class='line'>        <span class="k">while</span> <span class="o">(</span><span class="n">featureIndex</span> <span class="o">&lt;</span> <span class="n">numFeatures</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>          <span class="k">val</span> <span class="n">isFeatureContinuous</span> <span class="k">=</span> <span class="n">metadata</span><span class="o">.</span><span class="n">isContinuous</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">)</span>
</span><span class='line'>          <span class="k">if</span> <span class="o">(</span><span class="n">isFeatureContinuous</span><span class="o">)</span> <span class="o">{</span> <span class="c1">// Bins for categorical variables are already assigned.</span>
</span><span class='line'>            <span class="n">bins</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">)(</span><span class="mi">0</span><span class="o">)</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Bin</span><span class="o">(</span><span class="k">new</span> <span class="nc">DummyLowSplit</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">,</span> <span class="nc">Continuous</span><span class="o">),</span>
</span><span class='line'>              <span class="n">splits</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">)(</span><span class="mi">0</span><span class="o">),</span> <span class="nc">Continuous</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span>
</span><span class='line'>            <span class="k">for</span> <span class="o">(</span><span class="n">index</span> <span class="k">&lt;-</span> <span class="mi">1</span> <span class="n">until</span> <span class="n">numBins</span> <span class="o">-</span> <span class="mi">1</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>              <span class="k">val</span> <span class="n">bin</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Bin</span><span class="o">(</span><span class="n">splits</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">)(</span><span class="n">index</span><span class="o">-</span><span class="mi">1</span><span class="o">),</span> <span class="n">splits</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">)(</span><span class="n">index</span><span class="o">),</span>
</span><span class='line'>                <span class="nc">Continuous</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span>
</span><span class='line'>              <span class="n">bins</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">)(</span><span class="n">index</span><span class="o">)</span> <span class="k">=</span> <span class="n">bin</span>
</span><span class='line'>            <span class="o">}</span>
</span><span class='line'>            <span class="n">bins</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">)(</span><span class="n">numBins</span><span class="o">-</span><span class="mi">1</span><span class="o">)</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Bin</span><span class="o">(</span><span class="n">splits</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">)(</span><span class="n">numBins</span><span class="o">-</span><span class="mi">2</span><span class="o">),</span>
</span><span class='line'>              <span class="k">new</span> <span class="nc">DummyHighSplit</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">,</span> <span class="nc">Continuous</span><span class="o">),</span> <span class="nc">Continuous</span><span class="o">,</span> <span class="nc">Double</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">)</span>
</span><span class='line'>          <span class="o">}</span>
</span><span class='line'>          <span class="n">featureIndex</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>        <span class="o">(</span><span class="n">splits</span><span class="o">,</span> <span class="n">bins</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>      <span class="k">case</span> <span class="k">_</span> <span class="k">=&gt;</span> <span class="o">???</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Bin化（又叫数据规约、分桶）这个地方比较单纯，很少调用其他的函数。这里要先界定两个名词，split 和 bin。前者表示分裂的点，后者表示分裂的点之间的线段（样本集）。由于 bin 的个数通常都是有限制的，因此即便<code>requiredSamples</code>数目是 bin 个数的平方，也是可以将这些采样到的数据收回到 Driver 端的，即<code>sampledInput</code>。Bin 化采样的这个地方有点类似于 TeraSort。之后的第一个任务是根据采样的结果找到每个特征的可行的分裂点（split），这里就看出采样的作用来了，它实际上是一种数据规约，限定了分裂点只能由采样结果计算得来。代码中的<code>while</code>循环针对于每一个 feature，对于每个 feature，我们根据前面算出来的<code>stride</code>（步长）信息计算出一个个的分裂点。</p>

<p>代码的下半部分就是根绝得到的 split，找到其对应的所有的 bin。把 split 理解成点，则 bin 就是两点之间的线段，因此，只要给定两个端点就能确定一个 bin。遇到开头和结尾的地方，会用哑元<code>DummyLowSplit</code>和<code>DummyHighSplit</code>代替。</p>

<p>划分了 split 和 bin 最大的好处就是分裂点由数据表中所有的表项减少到所有的 split，而在计算一些统计量的时候 bin 可以减少计算量，每个 bin 内部直接归约。</p>

<p>下一步就是在 split 之中寻找最佳的分裂点。这里是一个循环，每次循环都会完成一棵树的一个完整的层次的节点的计算。当然，随着树的深度不断加深，节点的数目成倍增长，因此这里用到了一点小小的技巧：设定一个最大可同时处理的节点数目，如果那一层的节点数超过了这个范围，那么就层内分组进行训练，因此下面我们不再分析<code>findBestSplits</code>的代码，转而直接分析它所调用的<code>findBestSplitsPerGroup</code>。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'>  <span class="k">private</span> <span class="k">def</span> <span class="n">findBestSplitsPerGroup</span><span class="o">(</span>
</span><span class='line'>      <span class="n">input</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">TreePoint</span><span class="o">],</span>
</span><span class='line'>      <span class="n">parentImpurities</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">],</span>
</span><span class='line'>      <span class="n">metadata</span><span class="k">:</span> <span class="kt">DecisionTreeMetadata</span><span class="o">,</span>
</span><span class='line'>      <span class="n">level</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span>
</span><span class='line'>      <span class="n">nodes</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Node</span><span class="o">],</span>
</span><span class='line'>      <span class="n">splits</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Array</span><span class="o">[</span><span class="kt">Split</span><span class="o">]],</span>
</span><span class='line'>      <span class="n">bins</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Array</span><span class="o">[</span><span class="kt">Bin</span><span class="o">]],</span>
</span><span class='line'>      <span class="n">timer</span><span class="k">:</span> <span class="kt">TimeTracker</span><span class="o">,</span>
</span><span class='line'>      <span class="n">numGroups</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="mi">1</span><span class="o">,</span>
</span><span class='line'>      <span class="n">groupIndex</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="mi">0</span><span class="o">)</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[(</span><span class="kt">Split</span>, <span class="kt">InformationGainStats</span><span class="o">)]</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">val</span> <span class="n">bestSplits</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Array</span><span class="o">[(</span><span class="kt">Split</span>, <span class="kt">InformationGainStats</span><span class="o">)](</span><span class="n">numNodes</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">var</span> <span class="n">node</span> <span class="k">=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="k">while</span> <span class="o">(</span><span class="n">node</span> <span class="o">&lt;</span> <span class="n">numNodes</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">nodeImpurityIndex</span> <span class="k">=</span> <span class="o">(</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="n">level</span><span class="o">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">node</span> <span class="o">+</span> <span class="n">groupShift</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">binsForNode</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="n">getBinDataForNode</span><span class="o">(</span><span class="n">node</span><span class="o">)</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">parentNodeImpurity</span> <span class="k">=</span> <span class="n">parentImpurities</span><span class="o">(</span><span class="n">nodeImpurityIndex</span><span class="o">)</span>
</span><span class='line'>      <span class="n">bestSplits</span><span class="o">(</span><span class="n">node</span><span class="o">)</span> <span class="k">=</span> <span class="n">binsToBestSplit</span><span class="o">(</span><span class="n">binsForNode</span><span class="o">,</span> <span class="n">parentNodeImpurity</span><span class="o">)</span>
</span><span class='line'>      <span class="n">node</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>    <span class="n">bestSplits</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>面对一个 800 来行的程序，压力山大。首先把里面的函数定义、注释、log 全部删掉，先看主体，稍后再慢慢关注内部函数细节。首先，<code>bestSplits</code>是个数组，意味着决策树的当前层所有的节点都会计算一个最佳分裂点。下面的 while 循环就是对每个节点找到最佳分裂点。其中<code>binsForNode</code>的意思是找到当前节点中所有的 bin。如果把决策树的每个节点看做一个过滤，那么越往叶子节点走，每个节点所有的数据就越少，因为被过滤掉的越多。最后由<code>binsToBestSplit</code>这个函数找到当前节点中所有 bin 中选出的最佳分裂点。</p>

<p>看清了主干，下面按图索骥，先看<code>getBinDataForNode</code>是怎么回事：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">val</span> <span class="n">binMappedRDD</span> <span class="k">=</span> <span class="n">input</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="n">findBinsForLevel</span><span class="o">(</span><span class="n">x</span><span class="o">))</span>
</span><span class='line'>
</span><span class='line'><span class="k">val</span> <span class="n">binAggregates</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>  <span class="n">binMappedRDD</span><span class="o">.</span><span class="n">aggregate</span><span class="o">(</span><span class="nc">Array</span><span class="o">.</span><span class="n">fill</span><span class="o">[</span><span class="kt">Double</span><span class="o">](</span><span class="n">binAggregateLength</span><span class="o">)(</span><span class="mi">0</span><span class="o">))(</span><span class="n">binSeqOp</span><span class="o">,</span><span class="n">binCombOp</span><span class="o">)</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="n">getBinDataForNode</span><span class="o">(</span><span class="n">node</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">isClassification</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="o">???</span>
</span><span class='line'>  <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
</span><span class='line'>    <span class="c1">// Regression</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">shift</span> <span class="k">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">node</span> <span class="o">*</span> <span class="n">numBins</span> <span class="o">*</span> <span class="n">numFeatures</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">binsForNode</span> <span class="k">=</span> <span class="n">binAggregates</span><span class="o">.</span><span class="n">slice</span><span class="o">(</span><span class="n">shift</span><span class="o">,</span> <span class="n">shift</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">numBins</span> <span class="o">*</span> <span class="n">numFeatures</span><span class="o">)</span>
</span><span class='line'>    <span class="n">binsForNode</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>如果只看<code>getBinDataForNode</code>的逻辑的话，其实很简单，每个节点的<code>binsForNode</code>是由<code>binAggregates</code>这个变量中切了一块出来得到的。切的地方是<code>3 * node * numBins * numFeatures</code>，一共切掉<code>3 * numBins * numFeatures</code>这么大。所以关键在<code>binAggregates</code>是怎么生成的。</p>

<p>首先要说明<code>binAggregates</code>这个变量内部都有些什么吧。这个变量其实是个<code>Array[Double]</code>，其中约定好了结构，即对于每个节点中的每个 feature 的每个 bin 计算三个统计量，分别为 count，sum，以及sum<sup>2</sup>。统计这三个量的意思很明显，就是均值和方差。这也解释了上面那个貌似奇怪的切分边界。具体原始数据是怎么分割到每个节点的呢？答案在<code>findBinsForLevel</code>这个函数中。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">def</span> <span class="n">findBinsForLevel</span><span class="o">(</span><span class="n">labeledPoint</span><span class="k">:</span> <span class="kt">LabeledPoint</span><span class="o">)</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>  <span class="c1">// Calculate bin index and label per feature per node.</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">arr</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">](</span><span class="mi">1</span> <span class="o">+</span> <span class="o">(</span><span class="n">numFeatures</span> <span class="o">*</span> <span class="n">numNodes</span><span class="o">))</span>
</span><span class='line'>  <span class="n">arr</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span> <span class="k">=</span> <span class="n">labeledPoint</span><span class="o">.</span><span class="n">label</span>
</span><span class='line'>  <span class="k">var</span> <span class="n">nodeIndex</span> <span class="k">=</span> <span class="mi">0</span>
</span><span class='line'>  <span class="k">while</span> <span class="o">(</span><span class="n">nodeIndex</span> <span class="o">&lt;</span> <span class="n">numNodes</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">parentFilters</span> <span class="k">=</span> <span class="n">findParentFilters</span><span class="o">(</span><span class="n">nodeIndex</span><span class="o">)</span>
</span><span class='line'>    <span class="c1">// Find out whether the sample qualifies for the particular node.</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">sampleValid</span> <span class="k">=</span> <span class="n">isSampleValid</span><span class="o">(</span><span class="n">parentFilters</span><span class="o">,</span> <span class="n">labeledPoint</span><span class="o">)</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">shift</span> <span class="k">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">numFeatures</span> <span class="o">*</span> <span class="n">nodeIndex</span>
</span><span class='line'>    <span class="k">if</span> <span class="o">(!</span><span class="n">sampleValid</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="c1">// Mark one bin as -1 is sufficient.</span>
</span><span class='line'>      <span class="n">arr</span><span class="o">(</span><span class="n">shift</span><span class="o">)</span> <span class="k">=</span> <span class="nc">InvalidBinIndex</span>
</span><span class='line'>    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">var</span> <span class="n">featureIndex</span> <span class="k">=</span> <span class="mi">0</span>
</span><span class='line'>      <span class="k">while</span> <span class="o">(</span><span class="n">featureIndex</span> <span class="o">&lt;</span> <span class="n">numFeatures</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">isFeatureContinuous</span> <span class="k">=</span> <span class="n">strategy</span><span class="o">.</span><span class="n">categoricalFeaturesInfo</span><span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">).</span><span class="n">isEmpty</span>
</span><span class='line'>        <span class="n">arr</span><span class="o">(</span><span class="n">shift</span> <span class="o">+</span> <span class="n">featureIndex</span><span class="o">)</span> <span class="k">=</span> <span class="n">findBin</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">,</span> <span class="n">labeledPoint</span><span class="o">,</span><span class="n">isFeatureContinuous</span><span class="o">)</span>
</span><span class='line'>        <span class="n">featureIndex</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>    <span class="n">nodeIndex</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>  <span class="n">arr</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>这个函数的输入是原始数据中的每一个<code>LabeledPoint</code>，输出结果是一个数组，表示当前样本所有 feature 的所有 bin 划分。最终整体的<code>binMappedRDD</code>作用是确定每个样本的每个 feature 应该落到哪个 bin 里面。</p>

<p>剩下的事情要看<code>binSeqOp</code>和<code>binComOp</code>这两个函数了。这两个函数式<code>aggregate</code>算子的参数。前者表明在一个数据分片内如何统计数据，后这说明两个分片的结果如何做合并。下面我们剥离出一些函数来看：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">def</span> <span class="n">regressionBinSeqOp</span><span class="o">(</span><span class="n">arr</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">],</span> <span class="n">agg</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">])</span> <span class="o">{</span>
</span><span class='line'>  <span class="c1">// Iterate over all nodes.</span>
</span><span class='line'>  <span class="k">var</span> <span class="n">nodeIndex</span> <span class="k">=</span> <span class="mi">0</span>
</span><span class='line'>  <span class="k">while</span> <span class="o">(</span><span class="n">nodeIndex</span> <span class="o">&lt;</span> <span class="n">numNodes</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="c1">// Check whether the instance was valid for this nodeIndex.</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">validSignalIndex</span> <span class="k">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">numFeatures</span> <span class="o">*</span> <span class="n">nodeIndex</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">isSampleValidForNode</span> <span class="k">=</span> <span class="n">arr</span><span class="o">(</span><span class="n">validSignalIndex</span><span class="o">)</span> <span class="o">!=</span> <span class="nc">InvalidBinIndex</span>
</span><span class='line'>    <span class="k">if</span> <span class="o">(</span><span class="n">isSampleValidForNode</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="c1">// actual class label</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">label</span> <span class="k">=</span> <span class="n">arr</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
</span><span class='line'>      <span class="c1">// Iterate over all features.</span>
</span><span class='line'>      <span class="k">var</span> <span class="n">featureIndex</span> <span class="k">=</span> <span class="mi">0</span>
</span><span class='line'>      <span class="k">while</span> <span class="o">(</span><span class="n">featureIndex</span> <span class="o">&lt;</span> <span class="n">numFeatures</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="c1">// Find the bin index for this feature.</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">arrShift</span> <span class="k">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">numFeatures</span> <span class="o">*</span> <span class="n">nodeIndex</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">arrIndex</span> <span class="k">=</span> <span class="n">arrShift</span> <span class="o">+</span> <span class="n">featureIndex</span>
</span><span class='line'>        <span class="c1">// Update count, sum, and sum^2 for one bin.</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">aggShift</span> <span class="k">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">numBins</span> <span class="o">*</span> <span class="n">numFeatures</span> <span class="o">*</span> <span class="n">nodeIndex</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">aggIndex</span> <span class="k">=</span> <span class="n">aggShift</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">featureIndex</span> <span class="o">*</span> <span class="n">numBins</span> <span class="o">+</span> <span class="n">arr</span><span class="o">(</span><span class="n">arrIndex</span><span class="o">).</span><span class="n">toInt</span> <span class="o">*</span> <span class="mi">3</span>
</span><span class='line'>        <span class="n">agg</span><span class="o">(</span><span class="n">aggIndex</span><span class="o">)</span> <span class="k">=</span> <span class="n">agg</span><span class="o">(</span><span class="n">aggIndex</span><span class="o">)</span> <span class="o">+</span> <span class="mi">1</span>
</span><span class='line'>        <span class="n">agg</span><span class="o">(</span><span class="n">aggIndex</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="k">=</span> <span class="n">agg</span><span class="o">(</span><span class="n">aggIndex</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span> <span class="o">+</span> <span class="n">label</span>
</span><span class='line'>        <span class="n">agg</span><span class="o">(</span><span class="n">aggIndex</span> <span class="o">+</span> <span class="mi">2</span><span class="o">)</span> <span class="k">=</span> <span class="n">agg</span><span class="o">(</span><span class="n">aggIndex</span> <span class="o">+</span> <span class="mi">2</span><span class="o">)</span> <span class="o">+</span> <span class="n">label</span><span class="o">*</span><span class="n">label</span>
</span><span class='line'>        <span class="n">featureIndex</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>    <span class="n">nodeIndex</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">def</span> <span class="n">binCombOp</span><span class="o">(</span><span class="n">agg1</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">],</span> <span class="n">agg2</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">])</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">var</span> <span class="n">index</span> <span class="k">=</span> <span class="mi">0</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">combinedAggregate</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">](</span><span class="n">binAggregateLength</span><span class="o">)</span>
</span><span class='line'>  <span class="k">while</span> <span class="o">(</span><span class="n">index</span> <span class="o">&lt;</span> <span class="n">binAggregateLength</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">combinedAggregate</span><span class="o">(</span><span class="n">index</span><span class="o">)</span> <span class="k">=</span> <span class="n">agg1</span><span class="o">(</span><span class="n">index</span><span class="o">)</span> <span class="o">+</span> <span class="n">agg2</span><span class="o">(</span><span class="n">index</span><span class="o">)</span>
</span><span class='line'>    <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>  <span class="n">combinedAggregate</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>看了这两个函数，是不是感觉一目了然？前者把三个统计量聚合在<code>agg</code>这个数组中，后者来合并多个<code>agg</code>数组。</p>

<p>现在决策树当前层上所有节点都得到自己节点中数据的统计量了，下一步就是为每个节点寻找最佳分裂点了：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">def</span> <span class="n">binsToBestSplit</span><span class="o">(</span>
</span><span class='line'>    <span class="n">binData</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">Double</span><span class="o">],</span>
</span><span class='line'>    <span class="n">nodeImpurity</span><span class="k">:</span> <span class="kt">Double</span><span class="o">)</span><span class="k">:</span> <span class="o">(</span><span class="kt">Split</span><span class="o">,</span> <span class="kt">InformationGainStats</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">logDebug</span><span class="o">(</span><span class="s">&quot;node impurity = &quot;</span> <span class="o">+</span> <span class="n">nodeImpurity</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// Extract left right node aggregates.</span>
</span><span class='line'>  <span class="k">val</span> <span class="o">(</span><span class="n">leftNodeAgg</span><span class="o">,</span> <span class="n">rightNodeAgg</span><span class="o">)</span> <span class="k">=</span> <span class="n">extractLeftRightNodeAggregates</span><span class="o">(</span><span class="n">binData</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// Calculate gains for all splits.</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">gains</span> <span class="k">=</span> <span class="n">calculateGainsForAllNodeSplits</span><span class="o">(</span><span class="n">leftNodeAgg</span><span class="o">,</span> <span class="n">rightNodeAgg</span><span class="o">,</span> <span class="n">nodeImpurity</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">val</span> <span class="o">(</span><span class="n">bestFeatureIndex</span><span class="o">,</span><span class="n">bestSplitIndex</span><span class="o">,</span> <span class="n">gainStats</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="c1">// Initialize with infeasible values.</span>
</span><span class='line'>    <span class="k">var</span> <span class="n">bestFeatureIndex</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
</span><span class='line'>    <span class="k">var</span> <span class="n">bestSplitIndex</span> <span class="k">=</span> <span class="nc">Int</span><span class="o">.</span><span class="nc">MinValue</span>
</span><span class='line'>    <span class="k">var</span> <span class="n">bestGainStats</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">InformationGainStats</span><span class="o">(</span><span class="nc">Double</span><span class="o">.</span><span class="nc">MinValue</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="o">)</span>
</span><span class='line'>    <span class="c1">// Iterate over features.</span>
</span><span class='line'>    <span class="k">var</span> <span class="n">featureIndex</span> <span class="k">=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="k">while</span> <span class="o">(</span><span class="n">featureIndex</span> <span class="o">&lt;</span> <span class="n">numFeatures</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="c1">// Iterate over all splits.</span>
</span><span class='line'>      <span class="k">var</span> <span class="n">splitIndex</span> <span class="k">=</span> <span class="mi">0</span>
</span><span class='line'>      <span class="k">while</span> <span class="o">(</span><span class="n">splitIndex</span> <span class="o">&lt;</span> <span class="n">numBins</span> <span class="o">-</span> <span class="mi">1</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">gainStats</span> <span class="k">=</span> <span class="n">gains</span><span class="o">(</span><span class="n">featureIndex</span><span class="o">)(</span><span class="n">splitIndex</span><span class="o">)</span>
</span><span class='line'>        <span class="k">if</span> <span class="o">(</span><span class="n">gainStats</span><span class="o">.</span><span class="n">gain</span> <span class="o">&gt;</span> <span class="n">bestGainStats</span><span class="o">.</span><span class="n">gain</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>          <span class="n">bestGainStats</span> <span class="k">=</span> <span class="n">gainStats</span>
</span><span class='line'>          <span class="n">bestFeatureIndex</span> <span class="k">=</span> <span class="n">featureIndex</span>
</span><span class='line'>          <span class="n">bestSplitIndex</span> <span class="k">=</span> <span class="n">splitIndex</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>        <span class="n">splitIndex</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>      <span class="n">featureIndex</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>    <span class="o">(</span><span class="n">bestFeatureIndex</span><span class="o">,</span> <span class="n">bestSplitIndex</span><span class="o">,</span> <span class="n">bestGainStats</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">logDebug</span><span class="o">(</span><span class="s">&quot;best split bin = &quot;</span> <span class="o">+</span> <span class="n">bins</span><span class="o">(</span><span class="n">bestFeatureIndex</span><span class="o">)(</span><span class="n">bestSplitIndex</span><span class="o">))</span>
</span><span class='line'>  <span class="n">logDebug</span><span class="o">(</span><span class="s">&quot;best split bin = &quot;</span> <span class="o">+</span> <span class="n">splits</span><span class="o">(</span><span class="n">bestFeatureIndex</span><span class="o">)(</span><span class="n">bestSplitIndex</span><span class="o">))</span>
</span><span class='line'>
</span><span class='line'>  <span class="o">(</span><span class="n">splits</span><span class="o">(</span><span class="n">bestFeatureIndex</span><span class="o">)(</span><span class="n">bestSplitIndex</span><span class="o">),</span> <span class="n">gainStats</span><span class="o">)</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>至此看似复杂的决策树已经抽丝剥茧完毕。回顾一下，三个程序优化方法分别是</p>

<ul>
<li>以 aggregate 代替 shuffle 来计算统计量；</li>
<li>以 bin 来代替原始数据归约数据量；</li>
<li>层次化的模型训练代替逐节点的模型训练。</li>
</ul>


<p>其中最重要的是第二个优化，也就是本节重点想说的：<strong>人为的数据规约降低计算复杂度</strong>。</p>

<h2>结语</h2>

<p>最近有点懒，现在把拖了很久的这篇文章整理一下，聊表慰藉。本文原创的思想来源于 Spark Summit 2014 Xiangrui 和 Amde 两个讲座的 slide，都很有启发和借鉴的意义，因此整理一下放在这里。做了一年的 Spark，尤其是 MLlib，现在回头来看，为什么在 Spark 平台上写一个优秀的机器学习算法这么难？（这样说有点不公平，因为在 Hadoop 上实现会更烦琐。）或许真的是现有 Spark 的抽象不适合机器学习，但是迄今为止开源社区没有更好的分布式框架的抽象可以用了。也许各大互联网公司有自己的秘密武器，不过这就不得而知了。MLlib 的本意（从名字上来看）也许是想解放 machine learner，但是现在越来越走在解放 end user的道路上了。但我始终觉得这不是良策，因为 machine leaner 开发新的机器学习程序还是很难，这样导致整个系统不具有可扩展性。也许对于机器学习没有 all in one 这种让我们省力的抽象或者平台，也许 machine learner 就该在平台和算法的世界里继续努力的奋斗。</p>

<p>无论如何，好的思想值得借鉴和反思，也许本文值得一看！</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/06/17/spark-internals-deploy/">Spark Internals: Deploy, Scheduling and RDD</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-17T12:25:51+08:00" pubdate data-updated="true">Jun 17<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>This article is just for fun, please think carefully before reading!</strong></p>

<p>毫无疑问, 你将经历的是一次奇妙之旅. 在现有的分布式系统框架内, 如果非要挑选其一可以视为艺术, 那就是现在呈现在你眼前的. Spark, 在山寨风行的大数据/分布式开源市场内, 犹若火花闪现. 这永远不是终结, 而是开天辟地的第一团火光. 星星之火, 可以燎原.</p>

<p>然而, 我们不能过誉. 任何新技术的闪现都不是一蹴而就. 循环往复, 螺旋上升是技术的发展必由之途. 从百年之前的无线电技术发明, 到调频对调幅的憋屈之战, 未经开场便遭遇电视技术的碾压, 再到互联网的兴起无不展现一曲壮烈的华章. 对于Spark而言, 作为Apache开源社区旗下的一员悍勇, 是站在了巨象的肩膀上. 是的, 永远不容忽视Hadoop迄今为止的统治地位, 及其用于破旧立新的情怀.</p>

<p>两百年前科学巨匠巴贝奇的差分机, 和爱达·拜伦天才般智慧的编程思想, 两人以穿越般的身姿错生在那个不属于他们的文艺复兴时代. 百年后, 图灵, 丘奇, 冯诺依曼等计算机先哲开拓了新时代. 新千年后十年, 端设备的极大普及以及”长长的线路”极大发展, 给世界人们带来了珍宝般的财富, 所谓的21世纪黑金 – 数据. 驰骋在这个时代, 计算机的世界越来越有海贼王的精彩 – 财富就在那儿, 去拿吧! – 一个崭新的时代.</p>

<p>不同的是, 数据时代的one piece可不止一份. 或许是金钱诱惑的驱动(哪件技术的发展不是呢?), 或许带着一点贡献时代的情怀, 从21世纪头五年到现在, 计算机世界, 乃至全世界, 进入了大数据的时代.</p>

<p>每个胸怀数据之志的计算机人都在寻找one piece的通路. Hadoop/Spark等兴起无不是众望所归, 生逢其时. 平心而论, 大数据处理平台等带来的”新技术”并非都是新技术, 也肯定不是最精尖的那些. 然而, 那些高端的生不逢时的技术, 只能是恰如猛虎卧荒丘.</p>

<p>历经头5年Hadoop热潮的人们应该不会对此陌生: 一个由脚本语言粘合起来的世界. 我们写好各种code snippets, 打成jar包, 以shell script作为控制器, 以系统时间为salt制定输入输出路径, 串起逻辑流. SummingBird的出现或许可以减轻你的负担, 不过那也是近一两年的事情了. 在Spark的世界里, 我们要告诉大家的第一件事就是Driver.</p>

<p>或许你可以把Driver看做Hadoop世界中的shell script, 但又远远不止. 可以说是”虽不中, 亦不远矣”. 对于Spark用户来说, Driver无处不在: 当你打开Spark Shell的时候, 你就已经开始跟Driver打交道了. 当你写下<code>val a = 1</code> 这种简单的语句时, Driver就已经开始为你忙活了. 当然, Spark Shell中有一些特殊的情况, 当你在真正应用代码中执行到这句时, 其实, 几乎什么都没发生. 在这里, 你可以把Driver当做第一次与Spark交流的大门.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/06/17/spark-internals-deploy/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/03/11/crazy-small-files-in-hdfs/">Crazy Small Files in HDFS</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-03-11T16:28:47+08:00" pubdate data-updated="true">Mar 11<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>Background</h2>

<p>2 months ago, I intent to contribute a LDA algorithm to Spark, coordinate with my parallel machine learning paper. After I finished the core of LDA &ndash; the Gibbs sampling, I find that there are some trivial matters in the way of creating a usable LDA. Mostly, they are the pre-processing of text files. For the word segmentation, both Chinese and English, I wrap Lucene with a piece of scala code to support that, just like what <a href="http://www.scalanlp.org/">ScalaNLP</a> does. But the input format traps me lots of time.</p>

<p>The standard input format of Spark is from the interface called <code>textFiles(path, miniSplit)</code> in the <code>SparkContext</code> class. But it is a line processor, which digest one line each time. However what I want is a KV processor, i.e. I need an interface which can return me a KV pair (fileName, content) given a directory path. So I try to write my own <code>InputFormat</code>.</p>

<p>Firstly, I try to use the <code>lineReader</code> and handle the fragments of blocks myself, later I find that it&rsquo;s both ugly and unnecessary, just as the code list below. I have to glue them together with a fixed seperator &ndash; &lsquo;\n&rsquo;. Instead of that, I use a more low level interface named <code>FSDataInputStream</code> to read an entire block once time. However, there are still some details need to be improved. Here, let&rsquo;s begin our explore.</p>

<figure class='code'><figcaption><span>lineReader version RecordReader (the terrible version) - BatchFileRecordReader.java</span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class='java'><span class='line'>    <span class="cm">/**</span>
</span><span class='line'><span class="cm">     * Reads an entire block contents. Note that files which are larger than the block size of HDFS</span>
</span><span class='line'><span class="cm">     * are cut by HDFS, then there are some fragments. File names and offsets are keep in the key,</span>
</span><span class='line'><span class="cm">     * so as to recover entire files later.</span>
</span><span class='line'><span class="cm">     *</span>
</span><span class='line'><span class="cm">     * Note that &#39;\n&#39; substitutes all other line breaks, such as &quot;\r\n&quot;.</span>
</span><span class='line'><span class="cm">     */</span>
</span><span class='line'>    <span class="nd">@Override</span>
</span><span class='line'>    <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">next</span><span class="o">(</span><span class="n">BlockwiseTextWritable</span> <span class="n">key</span><span class="o">,</span> <span class="n">Text</span> <span class="n">value</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">key</span><span class="o">.</span><span class="na">fileName</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="na">getName</span><span class="o">();</span>
</span><span class='line'>        <span class="n">key</span><span class="o">.</span><span class="na">offset</span> <span class="o">=</span> <span class="n">pos</span><span class="o">;</span>
</span><span class='line'>        <span class="n">value</span><span class="o">.</span><span class="na">clear</span><span class="o">();</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">if</span> <span class="o">(</span><span class="n">pos</span> <span class="o">&gt;=</span> <span class="n">end</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="k">return</span> <span class="kc">false</span><span class="o">;</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>        <span class="n">Text</span> <span class="n">blockContent</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Text</span><span class="o">();</span>
</span><span class='line'>        <span class="n">Text</span> <span class="n">line</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Text</span><span class="o">();</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">while</span> <span class="o">(</span><span class="n">pos</span> <span class="o">&lt;</span> <span class="n">end</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>            <span class="n">pos</span> <span class="o">+=</span> <span class="n">reader</span><span class="o">.</span><span class="na">readLine</span><span class="o">(</span><span class="n">line</span><span class="o">);</span>
</span><span class='line'>            <span class="n">blockContent</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="n">line</span><span class="o">.</span><span class="na">getBytes</span><span class="o">(),</span> <span class="mi">0</span><span class="o">,</span> <span class="n">line</span><span class="o">.</span><span class="na">getLength</span><span class="o">());</span>
</span><span class='line'>            <span class="n">blockContent</span><span class="o">.</span><span class="na">append</span><span class="o">(</span><span class="n">LFs</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="n">LFs</span><span class="o">.</span><span class="na">length</span><span class="o">);</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">if</span> <span class="o">(</span><span class="n">totalLength</span> <span class="o">&lt;</span> <span class="n">blockContent</span><span class="o">.</span><span class="na">getLength</span><span class="o">())</span> <span class="o">{</span>
</span><span class='line'>            <span class="n">value</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">blockContent</span><span class="o">.</span><span class="na">getBytes</span><span class="o">(),</span> <span class="mi">0</span><span class="o">,</span> <span class="n">totalLength</span><span class="o">);</span>
</span><span class='line'>        <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
</span><span class='line'>            <span class="n">value</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">blockContent</span><span class="o">.</span><span class="na">getBytes</span><span class="o">());</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>        <span class="k">return</span> <span class="kc">true</span><span class="o">;</span>
</span><span class='line'>    <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>




</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/03/11/crazy-small-files-in-hdfs/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/01/18/how-to-use-spark-for-ml-algorithms-and-why/">How to Use Spark for ML Algorithms and Why ?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-01-18T16:33:43+08:00" pubdate data-updated="true">Jan 18<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>NOTE</strong> This PR is only a request for comments, since it introduces some minor incompatible interface change in MLlib.</p>

<p><strong>Update 2014-01-16</strong> The inner iteration counts of local optimization is also an important parameter, which is related to the convergence rate. I will add some new experiments about it ASAP.</p>

<p><strong>Update 2014-01-16 [2]</strong>Using <code>data.cache</code> brings a great performance gain, BSP+ is worse than original version then.</p>

<p><strong>Update 2014-01-17</strong> When we removing the straggler of BSP+, BSP+ is better than original version. Straggler comes from the <code>sc.textFile</code>, HDFS gives bad answer. Seems that SSP is more reasonable and useful now. Besides, inner iteration is also a big factor. For our data with 15 partitions, 60 seems to be the best inner iteration.</p>

<p>If there is no straggler at all, the costs caused by framework must be higher than the inner iteration expansion. Meanwhile, the uncertainty caused by high parallelism is made up by the acceleration.</p>

<p><strong>Update 2014-01-18</strong> We also find that there are some influences come from the partition number. As we said earlier, there is a inflection point.</p>

<p><strong>Update 2014-01-18 [2]</strong> We test SVM with BSP+, it runs cool. We also modify LASSO, RidgeRegression, LinearRegression.</p>

<p><strong>Update 2014-01-18 [3]</strong> BSP+ SVM beats original SVM 7 倍，是不是JobLogger或者时间的统计会影响性能？因为后者打印的log数量非常庞大。经过验证，阎栋加入的JobLogger没有那么严重的影响。由系统加入的TaskLog和DAGLog不知道怎么停。</p>

<p><strong>Update 2014-01-18 [4]</strong> 思考一个问题，为什么同样的工作量，60次混合会比传统的梯度下降要好？要能解释这一点。差异只在混合策略上，例如，我有一个想法，还没想清楚呢就跟别人说了，搞得大家都不明白。如果自己想清楚了，再跟别人说会更明白。</p>

<p><strong>Update 2014-01-18 [5]</strong> BSP+快的原因，因为同步次数少了，导致网络开销同比减少。所以结果比原始情况好。大大的提升通信量，才能展现出我们的优势。</p>

<p><strong>Update 2014-01-18 [6]</strong> 找了一个新数据，这份数据2000维度，30多个GB，比之前的unigram好，但又比trigram少，可见mllib之废物，1000w的维度就已经跪了！！这还做毛个大数据啊？本来像自己动手生成数据集，但是总感觉不好。网上找到一个新的。找新数据的目的就是增加维度，这样让每次迭代之间传输的数据量更大，我们的优势更加明显。</p>

<p><strong>factors we found</strong></p>

<ul>
<li>number of partitions</li>
<li>straggler (YJP profiling)</li>
<li>inner iteration</li>
<li>outer iteration</li>
</ul>


<p><strong>Two different usages of Spark present two different thoughts</strong></p>

<ul>
<li><p>The classic one is that we use Spark as a distributed code compiler, plus with a task dispatcher and executors. In this way, <a href="http://www.eecs.berkeley.edu/~keo/">Kay Ousterhout</a> publish a paper called <a href="http://www.cs.berkeley.edu/~matei/papers/2013/sosp_sparrow.pdf">Sparrow: Distributed, Low Latency Scheduling</a> is the future. However, I don&rsquo;t think it is the best practice of Spark. The <a href="https://spark-project.atlassian.net/browse/SPARK-1006">DAG scheduler stack overflow</a> is also a big question as mentioned by <a href="http://www.cs.berkeley.edu/~matei/">Matei Zaharia</a>.</p></li>
<li><p>A more natural way to use Spark W.R.T. machine learning is treat Spark as a effective distributed executive container. Data with cache stay in each executor, computing flow over these data, and feedback parameters to drivers again and again.</p></li>
</ul>


</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/01/18/how-to-use-spark-for-ml-algorithms-and-why/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/01/17/adl45-meeting-record/">ADL45 Meeting Record</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-01-17T18:49:47+08:00" pubdate data-updated="true">Jan 17<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>引子</h2>

<p>12月17-18日参加了计算机学会组织的<a href="http://www.ccf.org.cn/sites/ccf/xhdtnry.jsp?contentId=2771337645909">推荐系统前沿课程</a>，来自工业界和学术界前沿的诸位专家大牛们分享了实践和理论模型等。受益良多，趁着余热先给大家一个介绍，稍后我拿到了slides可以继续完善。疏漏之处在所难免，还请大家谅解。
课程列表：</p>

<ol>
<li><p>Social recommendation systems 诺亚方舟实验室 杨强</p></li>
<li><p>电子商务中的个性化技术 阿里妈妈广告事业部总监 初敏</p></li>
<li><p>推荐系统实践和挑战：以阿里巴巴、百分点科技为例 电子科技大学 周涛</p></li>
<li><p>Critiquing-based recommender systems and user experiences 香港浸会大学 陈黎</p></li>
<li><p>情景感知的信息推荐 中国科技大学 陈恩红</p></li>
<li><p>Cross-domain link prediction and recommendation 清华大学 唐杰</p></li>
<li><p>搜索广告的拍卖机制设计 MSRA 刘铁岩</p></li>
</ol>


<p>先说心得，总体来看，推荐系统这个领域，学术界单干拼不过工业界，工业界单个拼不过学术界工业界的合体。刘铁岩老师这次游离在外，讲的是博弈论。这几大talk基本涵盖推荐系统发展方向，其中不乏小众产品，但整体对方向和故事的把握都是不错的，可能会皮厚馅薄，不过对得起“前沿”这个词，很具有指导意义。</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/01/17/adl45-meeting-record/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/01/17/petuum-source-code-read-and-initial-test-result/">Petuum: Source Code Read and Initial Test Result</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-01-17T18:40:01+08:00" pubdate data-updated="true">Jan 17<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>这几天为了测好<a href="http://petuum.org/">Petuum</a>，花了一点时间看了一下Petuum源码，把其中的精华跟大家分享一下。</p>

<p>Petuum共有9050行代码，代码文件数39个。整个Petuum这么多源码，其实就只实现了一个LDA，外加一个Hello world。目前没有一个pull request和issue，另外已经很久（20天）没有更新了。发现C++写的在github上不是很受欢迎，GraphLab也很少有pull request。相比之下Spark的Pull request之多，热度完全不同。</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/01/17/petuum-source-code-read-and-initial-test-result/">Read on &rarr;</a>
    </footer>
  


    </article>
  
  <div class="pagination">
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>About Me</h1>
  <p>When machine learning meets system.</p>
  <p>新浪微博: <a href="http://weibo.com/yinxusen">@yinxusen</a><br/>
     LinkedIn: <a href="http://www.linkedin.com/in/xusenyin">Xusen Yin</a><br/>
     Github: <a href="https://github.com/yinxusen">@yinxusen</a>
  </p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/08/20/mllib-sparsity/">MLlib：归约数据量</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/06/17/spark-internals-deploy/">Spark Internals: Deploy, Scheduling and RDD</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/11/crazy-small-files-in-hdfs/">Crazy Small Files in HDFS</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/01/18/how-to-use-spark-for-ml-algorithms-and-why/">How to Use Spark for ML Algorithms and Why ?</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/01/17/adl45-meeting-record/">ADL45 Meeting Record</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - Xusen -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
